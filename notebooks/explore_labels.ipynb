{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = pd.read_csv(\"../dataset/saxony-labeled-data/human-labels.csv\", dtype={\"post_id\": str})\n",
    "human_labels = (\n",
    "    human_labels.sort_values(by=\"timestamp\")\n",
    "    .rename(columns={\"is_saxony_election\": \"is_saxony\", \"is_saxony_election_comment\": \"is_saxony_comment\"}) # The column name was wrong while saving, but the UI correctly displayed that it does not HAVE to be politics in saxony\n",
    "    .groupby([\"post_id\", \"classification_by\"])\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "print(len(human_labels))\n",
    "human_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary_series(s: pd.Series):\n",
    "    assert s.isin([\"yes\", \"no\"]).all()\n",
    "    return s.map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "def get_means(labels_df: pd.DataFrame, question: str):\n",
    "    labels_df = labels_df.assign(question_binary=to_binary_series(labels_df[question]))\n",
    "    return labels_df.groupby(\"post_id\")[\"question_binary\"].mean()\n",
    "\n",
    "questions = [\"is_political\", \"is_saxony\", \"is_intolerant\", \"is_hedonic_entertainment\", \"is_eudaimonic_entertainment\"]\n",
    "comment_cols = [f\"{col}_comment\" for col in questions]\n",
    "q_mens = {q: get_means(human_labels, question=q) for q in questions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "human_hist_data = {}\n",
    "for question, means in q_mens.items():\n",
    "    counts = means.value_counts(normalize=True)\n",
    "    human_hist_data[question] = (counts.index, counts.values)\n",
    "\n",
    "def plot_question_hists(hist_data: dict[str, tuple[np.ndarray, np.ndarray]]):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(16, 2.5))\n",
    "    fig.tight_layout(pad=3.0)\n",
    "\n",
    "    for ax, (question, (x_vals, y_vals)) in zip(axes, hist_data.items()):\n",
    "        ax.bar(x_vals, y_vals, width=0.05)\n",
    "        ax.set_title(question)\n",
    "        ax.set_ylabel(\"Fraction\")\n",
    "        ax.set_xlabel(\"No=0 or Yes=1\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(alpha=0.5)\n",
    "\n",
    "plot_question_hists(human_hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difficulty_score(df: pd.DataFrame):\n",
    "    difficulty = (1 - ((df - 0.5).abs() / 0.5)).mean(axis=1).sort_values(ascending=False)\n",
    "    return difficulty\n",
    "\n",
    "difficulty = difficulty_score(pd.DataFrame(q_mens))\n",
    "difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_counts = difficulty.value_counts()\n",
    "print(diff_counts)\n",
    "plt.bar(diff_counts.index, diff_counts.values, width=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_answers_by_post = human_labels.groupby(\"post_id\")[questions].nunique().max(axis=1)\n",
    "hard_posts = unique_answers_by_post[unique_answers_by_post > 1]\n",
    "easy_posts = unique_answers_by_post[unique_answers_by_post == 1]\n",
    "print(len(hard_posts), len(easy_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does AI perform on the easy posts?\n",
    "We assume here the ground truth to be the human labels, which are unique by construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai_labels = pd.read_csv(\"../dataset/generated-ai-labels/model_labels_openbmb_MiniCPM-V-2_6_03_17_25.csv\")\n",
    "ai_labels = pd.read_csv(\"../results-gemma-3-12b-it/model_labels.csv\", dtype={\"post_id\": str})\n",
    "# ai_labels[\"post_id\"] = ai_labels[\"post_id\"].str[-19:]\n",
    "print(len(ai_labels.columns))\n",
    "# print(ai_labels.columns)\n",
    "ai_labels = ai_labels[[\"post_id\", *questions, *comment_cols]]\n",
    "complete_ai_labels = ai_labels[~ai_labels[questions].isna().any(axis=1)]\n",
    "print(len(complete_ai_labels))\n",
    "\n",
    "human_labels_easy_set = human_labels.query(\"post_id in @easy_posts.index\")[[\"post_id\", *questions]].drop_duplicates()\n",
    "human_labels_easy_set\n",
    "joined = pd.merge(\n",
    "    pd.melt(human_labels_easy_set, id_vars=\"post_id\", value_vars=questions),\n",
    "    pd.melt(complete_ai_labels, id_vars=\"post_id\", value_vars=questions),\n",
    "    on=[\"post_id\", \"variable\"],\n",
    "    suffixes=(\"_human\", \"_ai\"),\n",
    "    how=\"inner\"\n",
    ").assign(\n",
    "    is_correct=lambda df: df[\"value_human\"] == df[\"value_ai\"]\n",
    ")\n",
    "joined.groupby(\"variable\")[\"is_correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Why is is_saxony so bad? Pretty much random\n",
    "# The model always erred on \"yes\" while the human labels were \"no\"\n",
    "# after looking at individual failures in detail its clear that the model mixes up Germany for Saxony, so answers\n",
    "# \"yes\" whenever it finds a mention or association with Germany.\n",
    "\n",
    "# Why is hedonic_entertainment so bad?\n",
    "# After looking at failures, it seems that the model does not code music (most likely because it cannot process audio!)\n",
    "ai_bad = joined.query(\"not is_correct and variable == 'is_intolerant'\")\n",
    "ai_bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_hist_data = {}\n",
    "for question in questions:\n",
    "    counts = to_binary_series(complete_ai_labels[question]).value_counts(normalize=True)\n",
    "    ai_hist_data[question] = (counts.index, counts.values)\n",
    "\n",
    "plot_question_hists(ai_hist_data)\n",
    "plot_question_hists(human_hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_col = \"is_intolerant\"\n",
    "q_col_comment = \"is_intolerant_comment\"\n",
    "for _, row in complete_ai_labels.query(\"post_id.isin(@ai_bad.post_id)\")[[\"post_id\", q_col_comment, q_col]].iterrows():\n",
    "    print(row[\"post_id\"])\n",
    "    print(row[q_col_comment])\n",
    "    print(row[q_col])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
